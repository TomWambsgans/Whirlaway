\documentclass{article}

\usepackage[english]{babel}

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{booktabs}

\newcommand{\Fp}{\mathbb F_p}
\newcommand{\Fq}{\mathbb F_q}
\newcommand{\Pol}{T}

\title{Whirlaway}
\author{Thomas Coratger, Tom Wambsgans}
\date{}
\begin{document}
\maketitle

\section{Introduction}

Whirlaway is a hash-based SNARK focusing on lightweight proofs, powered by the WHIR Polynomial Commitment Scheme \cite{whir}. The implementation is still in progress and can be found \href{https://github.com/TomWambsgans/Whirlaway}{here}. In this document, we explain how the proof system works. Nothing is fundamentally new, simply the combination of several recent techniques (WHIR, Ring-Switching, Sumcheck /  Univariate Skip).

\section{Notations and Symbols}

\begin{itemize}
    \item $log$ is always in base 2
    \item $[i]_2$: big-endian bit decomposition of an integer $i$
    \item $eq(x, y) := \prod_{i = 1}^{n} (x_i y_i + (1 - x_i) (1 - y_i))$, for $x$ and $y$ in $\mathbb F^n$. This "equality multilinear polynomial" verifies: $eq(x, y) = 1$ if $x = y$, $0$ otherwise, for $x$ and $y$ both sampled on the hypercube $\{0, 1\}^n$.
    \item $\Fp$: base field, typically KoalaBear ($p = 2^{31} - 2^{24} + 1$), or BabyBear ($p = 2^{31} - 2^{27} + 1$)
    \item $\Fq$: extension field ($q = p^{2^\kappa}$)
    \item $M$ $(\text{resp. } M')$: number of columns (resp. non-preprocessed columns) in the AIR table
    \item $m$ $(\text{resp. } m')$: smallest integer such that $2^m \geq M$ (resp. $2^{m'} \geq M'$)
    \item $N = 2^n$: number of rows in the AIR table
    \item $h_1, \dots, h_u$: transition constraints
    \item $H$: batched constraint ($H := \sum_{i=0}^{u-1} h_i \alpha^i $)
    \item $\Pol$: multilinear polynomial in $\Fp$ encoding all the (non-preprocessed) columns, with $n + m'$ variables
\end{itemize}

\section{Arithmetization}

\subsection{AIR}

We use AIR arithmetization (Algebraic Intermediate Representation). The witness consists of a list of $M$ columns $c_0, \dots, c_{M-1}$. Each column contains $N = 2^n$ elements if $\Fp$ (we use a power of 2 for simplicity). The goal of the prover is to convince the verifier that the table respects a set of $u$ transition constraints $h_0, \dots h_{u-1}$. Each constraint $h$ is a polynomial in $2 M$ variables, which is respected if for all rows $r \in \{0, \dots, N-2\}$: 

$$h(c_0[r], \dots, c_{M-1}[r], c_0[r+1], \dots, c_{M-1}[r+1]) = 0$$

\subsection{Preprocessed columns}

Traditional AIR systems allow the verifier to fix certain cells in the table (see "boundary conditions" \href{https://aszepieniec.github.io/stark-anatomy/stark}{here}). For technical reasons, we use a slightly different approach: we allow the verifier to fix certain columns, potentially sparse (called "preprocessed columns"). The work of the verifier associated to each preprocessed column is proportional to its number of nonzero rows. We denote by $c_0, \dots, c_{M'-1}$ the non-preprocessed columns and $c_{M'}, \dots, c_{M-1}$ the preprocessed ones.

\subsection{Example: Fibonacci sequence}

Let's say the prover wants to convince the verifier that the $N$-th values of the Fibonacci sequence equals $F_N$. We use $M = 4$ columns:

The first $M' = 2$ columns $c_0$ and $c_1$ contain the values of the Fibonacci sequence, which is guaranteed by the constraints:

\begin{itemize}
    \item $h_0(X_0^{\text{up}}, X_1^{\text{up}}, -, -, -, X_1^{\text{down}}, -, -) = X_1^{\text{down}} - (X_0^{\text{up}} + X_1^{\text{up}})$
 \item $h_1(-, X_1^{\text{up}}, -, -, X_0^{\text{down}}, -, -, -) = X_0^{\text{down}} - X_1^{\text{up}}$
\end{itemize}

 The last two columns $c_2$ and $c_3$ are "preprocessed": their content is enforced by the verifier. In our case we set $c_2 = [1, 0, \dots, 0]$ and $c_3 = [0, \dots, 0, 1]$. We finally use the following constraints, to ensure that the 2 initial values of the sequence are correct ($0$ and $1$), and that the final value equals $F_N$:

 \begin{itemize}
    \item $h_2(X_0^{\text{up}}, -, X_2^{\text{up}}, -, -, -, -, -) =   X_2^{\text{up}} \cdot X_0^{\text{up}}$ 
     \item $h_3(-, X_1^{\text{up}}, X_2^{\text{up}}, -, -, -, -, -) =  X_2^{\text{up}} \cdot (X_1^{\text{up}} - 1) $ 

(When the selector $c_2 \neq 0$ (which turns out to be the case at the initial row), we necessarily have $c_0 = 0$ and $c_1 = 1$)

 \item $h_4(X_0^{\text{up}}, -, -, X_3^{\text{up}}, -, -, -, -) = X_3^{\text{up}} \cdot (X_0^{\text{up}} - F_n)$ 

(When the selector $c_3 \neq 0$ (which turns out to be the case at the final row), we necessarily have $c_0 = F_n$)

\end{itemize}

 Note that $c_2$ and $c_3$ are sparse, both contain only one non-zero index. As a consequence, they have a negligible impact on the verification time.

\begin{table}[h!]
\centering
\caption{Fibonacci Sequence AIR Example}
\begin{tabular}{ccccc}
\toprule
Row & $c_0$ & $c_1$ & $c_2$ (preproc.) & $c_3$ (preproc.) \\
\midrule
0 & \cellcolor{blue!10}0 & \cellcolor{blue!10}1 & \cellcolor{orange!10}1 & \cellcolor{orange!10}0 \\
1 & \cellcolor{blue!10}1 & \cellcolor{blue!10}1 & \cellcolor{orange!10}0 & \cellcolor{orange!10}0 \\
2 & \cellcolor{blue!10}1 & \cellcolor{blue!10}2 & \cellcolor{orange!10}0 & \cellcolor{orange!10}0 \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
N-1 & \cellcolor{blue!10}$F_N$ & \cellcolor{blue!10}$F_{N+1}$ & \cellcolor{orange!10}0 & \cellcolor{orange!10}1 \\
\bottomrule
\end{tabular}

\vspace{1em}
\end{table}

\section{Proving system}

\subsection{{Commitment}}

Contrary to most of the STARK systems, which use a univariate Polynomial Commitment Scheme (PCS), like FRI or KZG, we use instead a multilinear\footnote{a multivariate polynomial with degree at most one in each variable} PCS: WHIR \cite{whir}. The entire AIR table is encoded and committed as a single multilinear polynomial $\Pol$ (except for the preprocessed columns, which are not committed). $\Pol$ has $n + m'$ variables, where $n = \log N = \log \text{(number of rows)}$ and $m' = \left\lceil  \log M' \right\rceil = \left\lceil  \log \text{(number of non-preprocessed columns)} \right\rceil$. $\Pol$ is defined in the lagrange basis (by its evaluations on the hypercube).

For every (non-preprocessed) column $i$ ($0 \leq i < M'$), for every row $r$ ($0 \leq r < N$): 

$$\Pol([i]_2 [r]_2) := c_{i}[r]$$

Where $[i]_2$ and $[r]_2$ are the corresponding bit decomposition (big-endian) of $i$ and $r$ (e.g. $M' = 20, N = 128, i = 3, r = 33, [i]_2[r]_2 = (00011 | 0100001)$).

The undefined evaluations ($M' \leq i < 2^{m'}$) are irrelevant and can be set to zero.

Note that the coefficients of $\Pol$ are in the base field $\Fp$. The random evaluation point at which $\Pol$ will be queried later by the verifier is in the extension field $\Fq$ (for soundness). To avoid the "embedding overhead" of committing in the extension field, we use the \textbf{ring-switching} protocol (see section 3 of \cite{fri_binius}) to commit in the base field and open in the extension field.

\subsection{Batching the constraints}

After receiving the commitment to $\Pol$, the verifier sends a random scalar $\alpha \in \Fq$ to the prover. Except with small soundness error, we can replace the $u$ transition constraints by a single one: $H := \sum_{i=0}^{u-1} h_i \alpha^i $.

\subsection{Zerocheck} \label{zerocheck}

The main argument comes from \cite{ccs} (see also \cite{simple_multivariate_AIR}).

For each column $c$, we define the multilinear polynomials $c^{\text{up}}$ in $n$ variables by:

$$c^{\text{up}}([r]_2)  = \begin{cases}
			c[r] & \text{if } r \in \{0, \dots, N-2\}\\
            c[N-2] & \text{if } r = N-1
		 \end{cases}$$

Similarly, we define the multilinear polynomials $c^{\text{down}}$ in $n$ variables by:

$$c^{\text{down}}([r]_2)  = \begin{cases}
			c[r+1] & \text{if } r \in \{0, \dots, N-2\}\\
            c[N-1] & \text{if } r = N-1
		 \end{cases}$$

The batched constraint $H$ is respected on the table if and only if:

$$\begin{gathered}
\forall r \in \{0, \dots, N-2\}, \hspace{2mm} H(c_0[r], \dots, c_{M-1}[r], c_0[r+1], \dots, c_{M-1}[r+1]) = 0 \\
\Leftrightarrow\\
\forall r \in \{0, \dots, N-1\}, \hspace{2mm} H(c_0^{\text{up}}([r]_2), \dots, c_{M-1}^{\text{up}}([r]_2), c_0^{\text{down}}([r]_2), \dots, c_{M-1}^{\text{down}}([r]_2)) = 0
\end{gathered}$$

The last equality can be proven using a zerocheck (see \cite{hyperplonk}), assuming the verifier has oracle access to $c_0^{\text{up}}, \dots, c_{M-1}^{\text{up}}$ and $ c_0^{\text{down}}, \dots, c_{M-1}^{\text{down}}$, which will be addressed in \ref{shifted_mle}. The zerocheck is performed as follows:

\begin{itemize}
    \item The verifier sends a random vector $r \in (\Fq)^n$
    \item Prover and verifier run the sumcheck protocol to prove that:
    $$ \sum_{b \in \{0, 1\}^n} eq(b, r) \cdot H(c_0^{\text{up}}(b), \dots, c_{M-1}^{\text{up}}(b), c_0^{\text{down}}(b), \dots, c_{M-1}^{\text{down}}(b)) = 0 $$
    \item Let $\beta \in (\Fq)^n$ be the vector of random challenges sent during the sumcheck. The verifier needs to evaluate the expression inside the sum above for $b \xleftarrow{} \beta$.
    
    $eq(\beta, r)$ can be easily computed.
    
    To handle the other factor, the prover sends the claimed values of $c_0^{\text{up}}(\beta), \dots, c_{M-1}^{\text{up}}(\beta)$ and $c_0^{\text{down}}(\beta), \dots, c_{M-1}^{\text{down}}(\beta)$ (correctness will be addressed in \ref{shifted_mle}). Given these $2M$ values, the verifier can finally evaluate $H$, which concludes the zerocheck.
\end{itemize}

\subsection{Oracle access to \texorpdfstring{$\textbf{\textit{c}}^{\text{up}}$}{} and \texorpdfstring{$\textbf{\textit{c}}^{\text{down}}$}{}}\label{shifted_mle}

In \ref{zerocheck}, for each column $c_i$, the prover has sent two values: $\text{claim}^\text{up}_i$ and $\text{claim}^\text{down}_i$ respectively equal to $c_i^{\text{up}}(\beta)$ and $c_i^{\text{down}}(\beta)$ in the honest case. It is now time to prove the correctness of these $2M$ evaluations.

First, the verifier sends a random challenge $\gamma \in \Fq$. Except with small soundness error, the $2M$ claims can be reduced to the following:

\begin{equation}\label{eq1}
    \sum_{i = 0}^{M-1} (\gamma^i \cdot \text{claim}^\text{up}_i + \gamma^{i+M} \cdot \text{claim}^\text{down}_i) \stackrel{?}{=} \sum_{i = 0}^{M-1} (\gamma^i \cdot c_i^{\text{up}}(\beta) + \gamma^{i+M} \cdot c_i^{\text{down}}(\beta))
\end{equation}


The verifier can easily compute the left side. To handle the right side, the following protocol is used:

\subsubsection{\texorpdfstring{Expression of $\textbf{\textit{c}}^{\text{up}}$}{}}

For every column $c$, for every $r \in (\Fq)^n$, we have:

$$c^{\text{up}}(r) = \sum_{b \in \{0, 1\}^n} [\underbrace{eq(b, r) \cdot (1 - eq(r, (\underbrace{1, \dots, 1}_{n \text{ times}})) + eq((r, b), (\underbrace{1, \dots, 1}_{2n - 1 \text{ times}}, 0)}_{\text{shift}^{\text{up}}(r, b)}] \cdot \tilde{c}(b)) $$

Where $\tilde{c}$ represents the multilinear extension (MLE) of $c$.

\subsubsection{\texorpdfstring{Expression of $\textbf{\textit{c}}^{\text{down}}$}{}}

For every column $c$, for every $r \in (\Fq)^n$, we have:

$$c^{\text{down}}(r) = \sum_{b \in \{0, 1\}^n} [\underbrace{\text{next}(r, b) +  eq((r, b), (\underbrace{1, \dots, 1}_{2n \text{ times}}))}_{\text{shift}^{\text{down}}(r, b)}] \cdot \tilde{c}(b) $$

Where "next" is the multilinear polynomial in $2n$ variables defined on the hypercube by: 

$$\text{next}([x]_2 [y]_2)  = \begin{cases}
			1 & \text{if } y = x +1\\
            0 & \text{otherwise}
		 \end{cases} \text{ for every pair of n-bit integers } (x, y)$$

See section 5.1 of \cite{ccs} for more details.

\subsubsection{Yet another sumcheck}

The right side of (\ref{eq1}) can thus be expressed as:

$$\sum_{b \in \{0, 1\}^n} \underbrace{\sum_{i = 0}^{M-1} [\gamma^i \cdot \text{shift}^{\text{up}}(\beta, b) + \gamma^{i+M} \cdot \text{shift}^{\text{down}}(\beta, b) ] \cdot \tilde{c}_i(b)}_{\text{expr}(\beta, b)}$$

A second sumcheck (with respect to $b$) is used to compute this sum. Let $\delta \in (\Fq)^n$ be the corresponding vector of challenges. The verifier must finally evaluate $\text{expr}(\beta, \delta)$. Both $\text{shift}^{\text{up}}$ and $\text{shift}^{\text{down}}$ can be succinctly computed. It remains $(\tilde{c}_i(\delta))_{0 \leq i < M}$, the evaluations of the columns MLEs on a common point $\delta$.

\subsection{PCS opening}

The verifier evaluates by himself $(\tilde{c}_i(\delta))_{M' \leq i < M}$ on the preprocessed columns.

The prover sends to the verifier $(v_i)_{0 \leq i < M'}$, equal to $(\tilde{c}_i(\delta))_{0 \leq i < M'}$ in the honest case.

The verifier sends a vector $z$ of $m' = \left\lceil  \log M' \right\rceil$ random scalars in $\Fq$.

The verifier computes $\sum_{i \in \{0, 1\}^{m'}} eq(i, z) \cdot v_i$, then requests a PCS opening for $\Pol((z, \delta))$, and requires that both evaluations coincide.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Univariate skip}


The sumcheck protocol reduces a sum over a multivariate polynomial by sending a sequence of univariate polynomials. Traditionally, this is done one variable at a time, across $n$ rounds. However, only the first round happens fully in the base field $\Fp$ — later rounds require evaluating at verifier-sent points in the extension field $\Fq$, which is computationally more expensive.

The \emph{univariate skip} optimization (from \cite{univariate_skip}) leverages this asymmetry: by reorganizing the domain and algebraic structure, we can perform the first $k$ rounds of sumcheck all at once, entirely within $\Fp$. This leads to major efficiency improvements.


\subsection{Changing the evaluation domain}

Traditionally, all evaluations are performed over the Boolean hypercube $H^n = \{0,1\}^n$. To skip $k$ variables, we restructure the domain to:
\begin{equation}
    D \times H^{n - k}
\end{equation}
where:
\begin{itemize}
    \item $D \subset \Fp$ is a multiplicative subgroup of size $2^k$
    \item $H^{n - k}$ is the Boolean hypercube in the remaining $n - k$ variables
\end{itemize}

Each row of the table is now indexed by a pair $(x, \mathbf{y})$ with $x \in D$, $\mathbf{y} \in H^{n-k}$.

\subsection{Table columns as polynomials}

Each table column is reinterpreted as a polynomial:
\begin{equation}
f_i(x, \mathbf{y}) \in \Fp[x, y_0, \dots, y_{n-k-1}]
\end{equation}
such that:
\begin{itemize}
    \item $\deg_x f_i \leq |D| - 1$ (i.e. low-degree over $x$)
    \item $f_i$ is multilinear in each $y_j$
\end{itemize}

This is just a change of viewpoint: instead of thinking of table columns as defined over $H^n$, we interpolate them over $D \times H^{n-k}$.




\subsection{Constraint polynomial and composition}

Let the prover have $\ell$ table columns $f_0(x, \mathbf{y}), \dots, f_{\ell-1}(x, \mathbf{y})$ defined over the domain $D \times H^{n-k}$. These are low-degree in $x$ and multilinear in $\mathbf{y}$. A constraint polynomial is a function $C(z_0, \dots, z_{\ell-1})$ that expresses relations among columns. Composing it with the table polynomials gives:
\begin{equation}
C(x, \mathbf{y}) := C(f_0(x, \mathbf{y}), \dots, f_{\ell-1}(x, \mathbf{y}))
\end{equation}
This multivariate polynomial should vanish on all points of the table if the constraint is satisfied.

\paragraph{Example.} Consider $n = 2$, $k = 1$ (so $x \in D$ and $\mathbf{y} \in H^1 = \{0,1\}$), and $\ell = 2$ columns. Suppose the constraint is simply:
\begin{equation}
C(z_0, z_1) = z_1 - z_0
\end{equation}
This means, column 1 must equal column 0. Let $D = \{1, \omega\} \subset \Fp$ for some subgroup of size $2$ (e.g., $\omega^2 = 1$). The table is indexed by $(x, y) \in D \times \{0,1\}$, and might look like:

\begin{table}[h!]
\centering
\caption{Constraint $f_1(x, y) = f_0(x, y)$}
\begin{tabular}{ccccc}
\toprule
$x$ & $y$ & $f_0(x, y)$ & $f_1(x, y)$ & Constraint holds? \\
\midrule
$1$     & $0$ & 3 & 3 & Yes \\
$1$     & $1$ & 4 & 4 & Yes \\
$\omega$ & $0$ & 5 & 5 & Yes \\
$\omega$ & $1$ & 6 & 6 & Yes \\
\bottomrule
\end{tabular}
\end{table}

In this case, the composed polynomial is:
\begin{equation}
C(x, y) = f_1(x, y) - f_0(x, y)
\end{equation}
which vanishes on all $4$ points of $D \times H^1$. This confirms that the constraint is satisfied. This small example illustrates how table rows correspond to evaluations of low-degree polynomials, and how polynomial constraints can be reduced to checking vanishing over a structured domain.




\subsection{Constructing the skipped sumcheck polynomial}

TODO

Let the verifier send a random challenge vector $\boldsymbol{\alpha} \in \Fq^{n-k}$ for the $y$-variables. The prover computes the following univariate polynomial:
\begin{equation}
v(x) := \sum_{\mathbf{y} \in H^{n-k}} eq(\mathbf{y}, \boldsymbol{\alpha}) \cdot C(x, \mathbf{y})
\end{equation}
This is a standard sumcheck-style reduction: the verifier will later check that $v(x_0)$ equals the expected value at a randomly chosen $x_0 \in D$. The key point: this polynomial $v(x)$ encodes all $k$ skipped rounds at once. It is univariate, and its degree is at most:
\begin{equation}
\deg v(x) \leq d (|D| - 1) = d(2^k - 1)
\end{equation}
The prover can compute this using at most $d \cdot 2^k$ evaluations of $C(x, \mathbf{y})$, all in the base field $\Fp$.


% Optional subsection, not sure we need it
\subsection{Why this is cheaper}

Compare this to the naive approach where one attempts to skip $k$ rounds by constructing a multivariate polynomial $v(X_0, \dots, X_{k-1})$. That polynomial would require:
\begin{equation}
(d + 1)^k
\end{equation}
evaluations for interpolation — exponential in $k$. In contrast, the univariate skip produces a degree-$d(2^k - 1)$ polynomial that can be interpolated with only $O(2^k)$ evaluations, which scales much better.

\subsection{Verifier check}

The verifier:
\begin{itemize}
    \item sends $\boldsymbol{\alpha} \in \Fq^{n-k}$
    \item receives the univariate polynomial $v(x)$ from the prover
    \item samples a random $x_0 \in D$
    \item evaluates or requests an opening at $x_0$
\end{itemize}

This single round replaces $k$ rounds of classical sumcheck — and crucially, all the evaluations are in $\Fp$.

\subsection{Cost comparison}

Let $C_{\Fp}$ and $C_{\Fq}$ be the cost of evaluating the constraint in the base field and extension field respectively.

\begin{itemize}
    \item Standard sumcheck (with $k$ rounds):
    \begin{equation}
    \underbrace{2^{n - 1}(d - 1) C_{\Fp}}_{\text{round 0}} + \underbrace{2^{n - k}(d - 1)(2^{k - 1} - 1) C_{\Fq}}_{\text{rounds 1 to } k-1}
    \end{equation}

    \item Univariate skip (skip $k$ rounds):
    \begin{equation}
    \underbrace{2^{n - k}(d - 1)(2^k - 1) C_{\Fp}}_{\text{all done in base field}}
    \end{equation}
\end{itemize}


When $\Fq$ is significantly more expensive to evaluate in than $\Fp$ (as is typically the case), this optimization leads to substantial speedups.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TODO
% - section 4.4 gamma can be removed, by running 2M sumchecks in parallel ?


\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}